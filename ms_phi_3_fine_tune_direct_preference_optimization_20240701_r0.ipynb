{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74071,"status":"ok","timestamp":1719883241627,"user":{"displayName":"Soonmo Seong","userId":"02404557050924642238"},"user_tz":-540},"id":"weK9UyrsFdYh","outputId":"fa338261-62a4-4b55-b0ca-be6cf3cc1850"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/547.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.2/547.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.2/300.2 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow\u003c15.0.0a0,\u003e=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow\u003c16,\u003e=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q datasets trl peft bitsandbytes sentencepiece wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJGOUymKGskr"},"outputs":[],"source":["import os\n","os.kill(os.getpid(), 9)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15422,"status":"ok","timestamp":1719884766429,"user":{"displayName":"Soonmo Seong","userId":"02404557050924642238"},"user_tz":-540},"id":"Z64d02sfFpYi","outputId":"ac6a219b-bd03-4cae-86fc-b437d87e48a0"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W\u0026B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["import os\n","import gc\n","import torch\n","\n","import transformers\n","from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n","from datasets import load_dataset\n","from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n","from trl import DPOTrainer\n","import bitsandbytes as bnb\n","from google.colab import userdata\n","import wandb\n","\n","# Defined in the secrets tab in Google Colab\n","hf_token = userdata.get('huggingface')\n","wb_token = userdata.get('wandb')\n","wandb.login(key=wb_token)\n","\n","model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n","new_model = \"Phi-3-mini-4k-instruct-dpo_method1\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"d9tDRh9sGN_7","outputId":"e3380147-ac08-457b-b35f-ab322a202ece"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc4f04efcaf44ee584cbe43eda42f70f","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/196 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def chatml_format(example):\n","    # Format system\n","    if len(example['system']) \u003e 0:\n","        message = {\"role\": \"system\", \"content\": example['system']}\n","        system = tokenizer.apply_chat_template([message], tokenize=False)\n","    else:\n","        system = \"\"\n","\n","    # Format instruction\n","    message = {\"role\": \"user\", \"content\": example['question']}\n","    prompt = tokenizer.apply_chat_template([message], tokenize=False, add_generation_prompt=True)\n","\n","    # Format chosen answer\n","    chosen = example['chosen'] + \"\u003c|im_end|\u003e\\n\"\n","\n","    # Format rejected answer\n","    rejected = example['rejected'] + \"\u003c|im_end|\u003e\\n\"\n","\n","    return {\n","        \"prompt\": system + prompt,\n","        \"chosen\": chosen,\n","        \"rejected\": rejected,\n","    }\n","\n","# Load dataset\n","dataset = load_dataset(\"Intel/orca_dpo_pairs\")['train']\n","\n","# Save columns\n","original_columns = dataset.column_names\n","\n","# Tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"left\"\n","\n","# Format dataset\n","dataset = dataset.map(\n","    chatml_format,\n","    remove_columns=original_columns\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-c01XrMXdyma"},"outputs":[{"data":{"text/plain":["{'chosen': 'Midsummer House is a moderately priced Chinese restaurant with a 3/5 customer rating, located near All Bar One.\u003c|im_end|\u003e\\n',\n"," 'rejected': ' Sure! Here\\'s a sentence that describes all the data you provided:\\n\\n\"Midsummer House is a moderately priced Chinese restaurant with a customer rating of 3 out of 5, located near All Bar One, offering a variety of delicious dishes.\"\u003c|im_end|\u003e\\n',\n"," 'prompt': '\u003c|system|\u003e\\nYou are an AI assistant. You will be given a task. You must generate a detailed and long answer.\u003c|end|\u003e\\n\u003c|endoftext|\u003e\u003c|user|\u003e\\nGenerate an approximately fifteen-word sentence that describes all this data: Midsummer House eatType restaurant; Midsummer House food Chinese; Midsummer House priceRange moderate; Midsummer House customer rating 3 out of 5; Midsummer House near All Bar One\u003c|end|\u003e\\n\u003c|assistant|\u003e\\n'}"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["dataset[1]"]},{"cell_type":"markdown","metadata":{"id":"h48wYl3EOlAF"},"source":["## LoRA Hyperparameters\n","\n","* LoraConfig: LoRa(Low-Rank Adaptation) is a PEFT method that\n","split a large matrix into two smaller low-rank matrices in the attention layers, drastically reducing the number of parameters to be fine-tuned.\n","* r: rank, Lora attention dimension\n","* lora_alpha: the alpha parameter for lora scaling\n","* lora_dropout: the dropout probability for lora layers\n","* bias: bias type for lora. 'none', 'all', or 'lora_only'. 'all' or 'lora_only' - update the corresponding bias during training.\n","* task_type: The type of task to perform.\n","    * Overview of supported task type\n","        * SEQ_CLS = \"SEQ_CLS\"\n","        * SEQ_2_SEQ_LM = \"SEQ_2_SEQ_LM\"\n","        * CAUSAL_LM = \"CAUSAL_LM\"\n","        * TOKEN_CLS = \"TOKEN_CLS\"\n","        * QUESTION_ANS = \"QUESTION_ANS\"\n","        * FEATURE_EXTRACTION = \"FEATURE_EXTRACTION\"\n","* target_modules: the name of the modules to apply the adapter to. If this is specified, only the modules with th specified names will be replaced."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ai7UMuiyeKZ7"},"outputs":[],"source":["# LoRA configuration\n","peft_config = LoraConfig(\n","    r=16,\n","    lora_alpha=16,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=['k_proj', 'gate_proj', 'v_proj', 'up_proj', 'q_proj', 'o_proj', 'down_proj']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yvtB7a3Oerm-"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1e403db205f44fcb61d953dfa5df08c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/967 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"944ae42751534bb1bde7de7c1b720012","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1df62dd0a0d348c48a9899d46a66b30f","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cffe826f66e441dd92dabc336189a6f2","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d47c43d7e655474fbacded33666fdc68","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff202f51803745f9b4bb96e3316b5918","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07b644cfdfc241bab9ab92f8ef690a88","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/181 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c22a46660e5464385da37e5e9e0d8ee","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Model to fine-tune\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    torch_dtype=torch.float16,\n","    load_in_4bit=True\n",")\n","model.config.use_cache = False\n","\n","# Reference model\n","ref_model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    torch_dtype=torch.float16,\n","    load_in_4bit=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XB0eE4aDe5-v"},"outputs":[],"source":["from trl import DPOConfig\n","\n","# DPO configuration\n","training_args = DPOConfig(\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=4,\n","    gradient_checkpointing=True,\n","    learning_rate=5e-5,\n","    lr_scheduler_type=\"cosine\",\n","    max_steps=50,\n","    save_strategy=\"no\",\n","    logging_steps=1,\n","    output_dir=new_model,\n","    optim=\"paged_adamw_32bit\",\n","    warmup_steps=100,\n","    bf16=True,\n","    report_to=\"wandb\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"e-TXHfUnoS1f"},"source":["## Reference model with PEFT\n","1. method 1: simply create two instances of the model deach loading your adapter, working fine but inefficiently."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"16sJBii_fMR1"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_prompt_length, max_length, force_use_ref_model. Will not be supported from version '1.0.0'.\n","\n","Deprecated positional argument(s) used in DPOTrainer, please use the DPOConfig to set these arguments instead.\n","  warnings.warn(message, FutureWarning)\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:227: UserWarning: You passed `force_use_ref_model` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:358: UserWarning: You passed `max_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:371: UserWarning: You passed `max_prompt_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:411: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d717830311dc44c18bc3c896e81f5090","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/12859 [00:00\u003c?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["max_steps is given, it will override any value given in num_train_epochs\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msoonmo-seong\u001b[0m (\u001b[33msoonmo-seong-MegazoneCloud\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.17.3"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in \u003ccode\u003e/content/wandb/run-20240702_014808-kaj0ei5y\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run \u003cstrong\u003e\u003ca href='https://wandb.ai/soonmo-seong-MegazoneCloud/huggingface/runs/kaj0ei5y' target=\"_blank\"\u003ePhi-3-mini-4k-instruct-dpo_method1\u003c/a\u003e\u003c/strong\u003e to \u003ca href='https://wandb.ai/soonmo-seong-MegazoneCloud/huggingface' target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href='https://wandb.me/run' target=\"_blank\"\u003edocs\u003c/a\u003e)\u003cbr/\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at \u003ca href='https://wandb.ai/soonmo-seong-MegazoneCloud/huggingface' target=\"_blank\"\u003ehttps://wandb.ai/soonmo-seong-MegazoneCloud/huggingface\u003c/a\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at \u003ca href='https://wandb.ai/soonmo-seong-MegazoneCloud/huggingface/runs/kaj0ei5y' target=\"_blank\"\u003ehttps://wandb.ai/soonmo-seong-MegazoneCloud/huggingface/runs/kaj0ei5y\u003c/a\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","You are not running the flash-attention implementation, expect numerical differences.\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n","  warnings.warn(\n","Could not estimate the number of tokens of the input, floating-point operations will not be computed\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [50/50 09:47, Epoch 0/1]\n","    \u003c/div\u003e\n","    \u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n"," \u003ctr style=\"text-align: left;\"\u003e\n","      \u003cth\u003eStep\u003c/th\u003e\n","      \u003cth\u003eTraining Loss\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0.670700\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0.687300\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e0.675000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e0.700800\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e0.701400\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e0.709500\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e0.718000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e8\u003c/td\u003e\n","      \u003ctd\u003e0.675200\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e9\u003c/td\u003e\n","      \u003ctd\u003e0.736600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e10\u003c/td\u003e\n","      \u003ctd\u003e0.693600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e11\u003c/td\u003e\n","      \u003ctd\u003e0.739700\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e12\u003c/td\u003e\n","      \u003ctd\u003e0.719600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e13\u003c/td\u003e\n","      \u003ctd\u003e0.680300\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e14\u003c/td\u003e\n","      \u003ctd\u003e0.701800\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e15\u003c/td\u003e\n","      \u003ctd\u003e0.686100\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e16\u003c/td\u003e\n","      \u003ctd\u003e0.700000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e17\u003c/td\u003e\n","      \u003ctd\u003e0.685500\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e18\u003c/td\u003e\n","      \u003ctd\u003e0.692300\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e19\u003c/td\u003e\n","      \u003ctd\u003e0.688900\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e20\u003c/td\u003e\n","      \u003ctd\u003e0.689400\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e21\u003c/td\u003e\n","      \u003ctd\u003e0.665600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e22\u003c/td\u003e\n","      \u003ctd\u003e0.635200\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e23\u003c/td\u003e\n","      \u003ctd\u003e0.686500\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e24\u003c/td\u003e\n","      \u003ctd\u003e0.694000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e25\u003c/td\u003e\n","      \u003ctd\u003e0.647300\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e26\u003c/td\u003e\n","      \u003ctd\u003e0.656100\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e0.650600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e28\u003c/td\u003e\n","      \u003ctd\u003e0.634500\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e29\u003c/td\u003e\n","      \u003ctd\u003e0.637600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e30\u003c/td\u003e\n","      \u003ctd\u003e0.591700\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e31\u003c/td\u003e\n","      \u003ctd\u003e0.646300\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e32\u003c/td\u003e\n","      \u003ctd\u003e0.633300\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e33\u003c/td\u003e\n","      \u003ctd\u003e0.622000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e34\u003c/td\u003e\n","      \u003ctd\u003e0.590700\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e35\u003c/td\u003e\n","      \u003ctd\u003e0.588600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e36\u003c/td\u003e\n","      \u003ctd\u003e0.574000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e37\u003c/td\u003e\n","      \u003ctd\u003e0.573000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e38\u003c/td\u003e\n","      \u003ctd\u003e0.537600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e39\u003c/td\u003e\n","      \u003ctd\u003e0.537500\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e40\u003c/td\u003e\n","      \u003ctd\u003e0.561000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e41\u003c/td\u003e\n","      \u003ctd\u003e0.495500\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003e0.470000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e43\u003c/td\u003e\n","      \u003ctd\u003e0.517600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e44\u003c/td\u003e\n","      \u003ctd\u003e0.471800\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e45\u003c/td\u003e\n","      \u003ctd\u003e0.402100\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e46\u003c/td\u003e\n","      \u003ctd\u003e0.428500\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e47\u003c/td\u003e\n","      \u003ctd\u003e0.414100\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e48\u003c/td\u003e\n","      \u003ctd\u003e0.411500\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e49\u003c/td\u003e\n","      \u003ctd\u003e0.430900\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e50\u003c/td\u003e\n","      \u003ctd\u003e0.349800\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\u003cp\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=50, training_loss=0.6141337281465531, metrics={'train_runtime': 610.4974, 'train_samples_per_second': 1.31, 'train_steps_per_second': 0.082, 'total_flos': 0.0, 'train_loss': 0.6141337281465531, 'epoch': 0.06220839813374806})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Create DPO trainer\n","dpo_trainer = DPOTrainer(\n","    model,\n","    ref_model,\n","    args=training_args,\n","    train_dataset=dataset,\n","    tokenizer=tokenizer,\n","    peft_config=peft_config,\n","    beta=0.1,\n","    max_prompt_length=1024,\n","    max_length=1536,\n","    force_use_ref_model=True,\n",")\n","\n","# Fine-tune model with DPO\n","dpo_trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gGNZImgkmjUy"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4234392cdd3746baba4aae835e6c4151","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# Save artifacts\n","dpo_trainer.model.save_pretrained(\"final_checkpoint_method1\")\n","tokenizer.save_pretrained(\"final_checkpoint_method1\")\n","\n","# Flush memory\n","del dpo_trainer, model, ref_model\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","# Reload model in FP16 (instead of NF4)\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    return_dict=True,\n","    torch_dtype=torch.float16,\n",")\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# Merge base model with the adapter\n","model = PeftModel.from_pretrained(base_model, \"final_checkpoint_method1\")\n","model = model.merge_and_unload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yi7n2Thqujqk"},"outputs":[],"source":["# Save model and tokenizer\n","model.save_pretrained(new_model)\n","tokenizer.save_pretrained(new_model)\n","\n","# Push them to the HF Hub\n","model.push_to_hub(new_model, use_temp_dir=False, token=hf_token)\n","tokenizer.push_to_hub(new_model, use_temp_dir=False, token=hf_token)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GeQH7f4C-6hF"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZdTcvdtdKmeA"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNxeUnWxx8paVsx+hqxLBZy","gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0075261c89184a35b2f383e9ca4c0415":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b9d9004ed314de993031b718573b828":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9691be336b64813a3ee2c3c899c08d8","placeholder":"​","style":"IPY_MODEL_5e784e9ae24f446491156c2b8a8f1423","value":"Downloading readme: 100%"}},"0f305e0e83c643788cd99ba4c760f743":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf30eea927c6469eb1b82f5ba392da2c","max":196,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0075261c89184a35b2f383e9ca4c0415","value":196}},"3eabe88436d646e98d06cd277d93a2cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e784e9ae24f446491156c2b8a8f1423":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80d412a051614a25b78ca5f841449995":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b32ceef3804d4c368e2167f59fbb9f71","placeholder":"​","style":"IPY_MODEL_f18e7e21071e4f289ce6b6df67500465","value":" 196/196 [00:00\u0026lt;00:00, 14.4kB/s]"}},"b32ceef3804d4c368e2167f59fbb9f71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf30eea927c6469eb1b82f5ba392da2c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9691be336b64813a3ee2c3c899c08d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f18e7e21071e4f289ce6b6df67500465":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc4f04efcaf44ee584cbe43eda42f70f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b9d9004ed314de993031b718573b828","IPY_MODEL_0f305e0e83c643788cd99ba4c760f743","IPY_MODEL_80d412a051614a25b78ca5f841449995"],"layout":"IPY_MODEL_3eabe88436d646e98d06cd277d93a2cc"}}}}},"nbformat":4,"nbformat_minor":0}